from pathlib import Path
from pydantic import Field, BaseModel
from script2runner import CLI
from typing import List, Literal, Dict, ClassVar, Annotated, Optional
import yaml


from dafn.runner_helper import get_file_pattern_from_suffix_list, check_output_paths
    
class Args(CLI):
    """
        - Goal: Spikesorts a spikeinterface (usually preprocessed) recording. 
        - Technique: It applies kilosort4. 
        - Formats: Input and output formats are in the .zarr formats generated by spike interface.
    """
    recording_path: Annotated[Path, Field(
        description="Path to the folder containing the (usually preprocessed) recording",
        default="/data1/Data/SpikeSorting/...si.zarr", 
        json_schema_extra=dict(pattern=get_file_pattern_from_suffix_list([".si.zarr"]))
    )]
    sorter_name: Literal["kilosort4"] = "kilosort4"
    sorter_config_path: Annotated[Optional[Path], Field(
        description="Path to the yaml file containign additional params for the sorter",
        default=None, 
        json_schema_extra=dict(pattern=get_file_pattern_from_suffix_list([".si.zarr"]))
    )]
    output_path: Annotated[Path, Field(
        default="/filer2/T4b/Temporary/....si.zarr", 
        description="Location of the output by spikeinterface", 
        json_schema_extra=dict(pattern=get_file_pattern_from_suffix_list([".si.zarr"]))
    )]
    sorter_output_path: Annotated[Path, Field(
        default="/filer2/T4b/Temporary/....", 
        description="Location of the output by the sorter", 
        json_schema_extra=dict(pattern=get_file_pattern_from_suffix_list([]))
    )]
    allow_output_overwrite: bool = Field(default=False, description="If yes, erases the outputs if they exists before starting computation")
    _run_info: ClassVar = dict(conda_env="ss", cpu=5.0, memory=2.0, gpu=1.0)
    
args = Args()

from dafn.spike_sorting import spikesort
import spikeinterface as si

with check_output_paths([args.output_path, args.sorter_output_path], args.allow_output_overwrite) as [output_path, sorter_output_path]:
    rec : si.BaseRecording = si.load(args.recording_path)
    params = {} 
    if args.sorter_config_path:
        import yaml
        with args.sorter_config_path.open("r") as f:
            params = yaml.safe_load(f)
    print(rec)
    print(params)
    sorting = spikesort(rec, args.sorter_name, args.sorter_output_path, params)
    print(sorting)
    sorting.save(format="zarr", folder=output_path)
    